{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN9b5N5ivf0eI18cIn+dV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yucong-guo/cs224/blob/main/lec1_2%20word2vec/skip_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vJvGi4W3Y_Ei"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()"
      ],
      "metadata": {
        "id": "jJsPnIGhZGzq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "n_vocab = len(vocab)\n",
        "\n",
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\n",
        "\n",
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = raw_text[i]\n",
        "    target = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    data.append((context, target))\n",
        "data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGTQwnxgZWO-",
        "outputId": "2d47acd1-9f9e-4851-c12a-842ce391db47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('about', ['We', 'are', 'to', 'study']),\n",
              " ('to', ['are', 'about', 'study', 'the']),\n",
              " ('study', ['about', 'to', 'the', 'idea'])]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_target_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "metadata": {
        "id": "N2H0s-ZZZWTH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "n_embed = 100\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, n_embed)\n",
        "        self.output = nn.Linear(n_embed, n_vocab)\n",
        "        self.log_softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        x: size: (1,)\n",
        "        '''\n",
        "        x = self.embed(x) #(1,100)\n",
        "        scores = self.output(x) #(1,n_embed)\n",
        "        log_ps = self.log_softmax(scores) #(1,n_embed)\n",
        "\n",
        "        return log_ps"
      ],
      "metadata": {
        "id": "WbdtuBtmaFYT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = SkipGram(n_vocab, n_embed)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "#TRAINING\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        #context_vector = make_context_vector(context, word_to_ix)\n",
        "        target_vector = make_target_vector(target, word_to_ix) #(1,4)\n",
        "\n",
        "        log_probs = model(torch.tensor([word_to_ix[context]]))\n",
        "\n",
        "        for target in target_vector:\n",
        "\n",
        "          total_loss += loss_function(log_probs, torch.tensor((target,), dtype=torch.long))\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "0YvBKB4yaFba"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = 'People'\n",
        "\n",
        "a = model(torch.tensor([word_to_ix[context]]))\n",
        "#torch.topk(a.flatten(), 3).indices\n",
        "#Print result\n",
        "print(f'Context: {context}\\n')\n",
        "top_4_index = (torch.topk(a[0],3).indices)\n",
        "prediction = [ix_to_word[int(ix)] for ix in top_4_index]\n",
        "print(f'Prediction: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDBdem5Ds0d2",
        "outputId": "0b7302d3-2014-4556-e7e9-8912b799b820"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: People\n",
            "\n",
            "Prediction: ['a', 'create', 'program.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dntorj8Os0qW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}